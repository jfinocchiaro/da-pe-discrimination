@article{ramaswamy2016convex,
  title={Convex calibration dimension for multiclass loss matrices},
  author={Ramaswamy, Harish G and Agarwal, Shivani},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={397--441},
  year={2016},
  publisher={JMLR. org}
}
,
@article{ramaswamy2018consistent,
  title={Consistent algorithms for multiclass classification with an abstain option},
  author={Ramaswamy, Harish G and Tewari, Ambuj and Agarwal, Shivani and others},
  journal={Electronic Journal of Statistics},
  volume={12},
  number={1},
  pages={530--554},
  year={2018},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}
,
@incollection{finocchiaro2018convex,
title = {Convex Elicitation of Continuous Properties},
author = {Finocchiaro, Jessica and Frongillo, Rafael},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {10425--10434},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8241-convex-elicitation-of-continuous-properties.pdf}
}
,
@article{crammer2001algorithmic,
  title={On the algorithmic implementation of multiclass kernel-based vector machines},
  author={Crammer, Koby and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={2},
  number={Dec},
  pages={265--292},
  year={2001}
}
,
@article{bartlett2008classification,
  title={Classification with a reject option using a hinge loss},
  author={Bartlett, Peter L and Wegkamp, Marten H},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={Aug},
  pages={1823--1840},
  year={2008}
}
,
@incollection{ramaswamy2012classification,
title = {Classification Calibration Dimension for General Multiclass Losses},
author = {Ramaswamy, Harish G and Agarwal, Shivani},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {2078--2086},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4528-classification-calibration-dimension-for-general-multiclass-losses.pdf}
}

@article{yuan2010classification,
  title={Classification methods with reject option based on convex risk minimization},
  author={Yuan, Ming and Wegkamp, Marten},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Jan},
  pages={111--130},
  year={2010},
}

@book{grunbaum2013convex,
  title={Convex Polytopes},
  author={Gr{\"u}nbaum, Branko},
  volume={221},
  year={2013},
  publisher={Springer Science \& Business Media},
}
,
@article{yang2018consistency,
	author    = {Forest Yang and
	Sanmi Koyejo},
	title     = {On the Consistency of Top-k Surrogate Losses},
	journal   = {CoRR},
	volume    = {abs/1901.11141},
	year      = {2019},
	url       = {http://arxiv.org/abs/1901.11141},
	archivePrefix = {arXiv},
	eprint    = {1901.11141},
	timestamp = {Mon, 04 Feb 2019 08:11:03 +0100},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1901-11141},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
,
@inproceedings{lapin2016loss,
	title={Loss functions for top-k error: Analysis and insights},
	author={Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={1468--1477},
	year={2016}
}
,
@article{lapin2018analysis,
	title={Analysis and optimization of loss functions for multiclass, top-k, and multilabel classification},
	author={Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={40},
	number={7},
	pages={1533--1554},
	year={2018},
	publisher={IEEE}
}
,
@article{yu2018lovasz,
	title={The Lov{\'a}sz Hinge: A Novel Convex Surrogate for Submodular Losses},
	author={Yu, Jiaqian and Blaschko, Matthew B},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	year={2018},
	publisher={IEEE}
}
,
@article{yu2015lovaszarxiv,
  title={The Lov$\backslash$'asz Hinge: A Novel Convex Surrogate for Submodular Losses},
  author={Yu, Jiaqian and Blaschko, Matthew},
  journal={arXiv preprint arXiv:1512.07797},
  year={2015}
}
,
@article{zhang2018reject,
author = {Chong Zhang and Wenbo Wang and Xingye Qiao},
title = {On Reject and Refine Options in Multicategory Classification},
journal = {Journal of the American Statistical Association},
volume = {113},
number = {522},
pages = {730-745},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2017.1282372},

URL = { 
        https://doi.org/10.1080/01621459.2017.1282372
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2017.1282372
    
}
}
,
@inproceedings{hazan2010direct,
  title={Direct loss minimization for structured prediction},
  author={Hazan, Tamir and Keshet, Joseph and McAllester, David A},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1594--1602},
  year={2010}
}
,
@inproceedings{gao2011consistency,
  title={On the consistency of multi-label learning},
  author={Gao, Wei and Zhou, Zhi-Hua},
  booktitle={Proceedings of the 24th annual conference on learning theory},
  pages={341--358},
  year={2011}
}
,
@article{duchi2018multiclass,
	title={Multiclass classification, information, divergence and surrogate risk},
	author={Duchi, John and Khosravi, Khashayar and Ruan, Feng and others},
	journal={The Annals of Statistics},
	volume={46},
	number={6B},
	pages={3246--3275},
	year={2018},
	publisher={Institute of Mathematical Statistics}
}

@inproceedings{osokin2017structured,
	title={On structured prediction theory with calibrated convex surrogate losses},
	author={Osokin, Anton and Bach, Francis and Lacoste-Julien, Simon},
	booktitle={Advances in Neural Information Processing Systems},
	pages={302--313},
	year={2017}
}
,
@inproceedings{pires2013cost,
	title={Cost-sensitive multiclass classification risk bounds},
	author={Pires, Bernardo Avila and Szepesvari, Csaba and Ghavamzadeh, Mohammad},
	booktitle={International Conference on Machine Learning},
	pages={1391--1399},
	year={2013}
}
,
@inproceedings{boser1992training,
	title={A training algorithm for optimal margin classifiers},
	author={Boser, Bernhard E and Guyon, Isabelle M and Vapnik, Vladimir N},
	booktitle={Proceedings of the fifth annual workshop on Computational learning theory},
	pages={144--152},
	year={1992},
	organization={ACM}
}
,
@inproceedings{lapin2015top,
  title={Top-k multiclass SVM},
  author={Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
  booktitle={Advances in Neural Information Processing Systems},
  pages={325--333},
  year={2015}
}

@article{lu2008normal,
  title={Normal fans of polyhedral convex sets},
  author={Lu, Shu and Robinson, Stephen M},
  journal={Set-Valued Analysis},
  volume={16},
  number={2-3},
  pages={281--305},
  year={2008},
  publisher={Springer}
}
,
@book{vapnik1999nature,
	title={The nature of statistical learning theory},
	author={Vapnik, Vladimir},
	year={1999},
	publisher={Springer science \& business media}
}
,
@inproceedings{finocchiaro2019embedding,
	title={An Embedding Framework for Consistent Polyhedral Surrogates},
	author={Finocchiaro, Jessie and Frongillo, Rafael and Waggoner, Bo},
	booktitle={Advances in neural information processing systems},
	year={2019}
}
,
@inproceedings{ramaswamy2015hierarchical,
	title={Convex calibrated surrogates for hierarchical classification},
	author={Ramaswamy, Harish and Tewari, Ambuj and Agarwal, Shivani},
	booktitle={International Conference on Machine Learning},
	pages={1852--1860},
	year={2015}
}
,
@article{zhang2004statistical,
	title={Statistical behavior and consistency of classification methods based on convex risk minimization},
	author={Zhang, Tong},
	journal={Annals of Statistics},
	pages={56--85},
	year={2004},
	publisher={JSTOR}
}
,
@article{lin2004note,
	title={A note on margin-based loss functions in classification},
	author={Lin, Yi},
	journal={Statistics \& probability letters},
	volume={68},
	number={1},
	pages={73--82},
	year={2004},
	publisher={Elsevier}
}
,
@article{steinwart2007compare,
	title={How to compare different loss functions and their risks},
	author={Steinwart, Ingo},
	journal={Constructive Approximation},
	volume={26},
	number={2},
	pages={225--287},
	year={2007},
	publisher={Springer}
}
,
@book{hiriart2012fundamentals,
	title={Fundamentals of convex analysis},
	author={Hiriart-Urruty, Jean-Baptiste and Lemar{\'e}chal, Claude},
	year={2012},
	publisher={Springer Science \& Business Media}
}
,
@article{frongillo2018elicitation,
	title={Elicitation complexity of statistical properties},
	author={Frongillo, Rafael and Kash, Ian A},
	journal={arXiv preprint arXiv:1506.07212v2},
	year={2018}
},
@article{finocchiaro2020embedding,
title={Embedding Dimension of Polyhedral Losses},
author={Finocchiaro, Jessie and Frongillo, Rafael and Waggoner, Bo},
journal={The Conference on Learning Theory},
year={2020}
},

@inproceedings{reid2009surrogate,
  title={Surrogate regret bounds for proper losses},
  author={Reid, Mark D and Williamson, Robert C},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={897--904},
  year={2009}
},
@article{fisher1922mathematical,
	title={On the mathematical foundations of theoretical statistics},
	author={Fisher, Ronald A},
	journal={Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
	volume={222},
	number={594-604},
	pages={309--368},
	year={1922},
	publisher={The Royal Society London}
},
@book{gyorfi2006distribution,
	title={A distribution-free theory of nonparametric regression},
	author={Gy{\"o}rfi, L{\'a}szl{\'o} and Kohler, Michael and Krzyzak, Adam and Walk, Harro},
	year={2006},
	publisher={Springer Science \& Business Media}
},
@article{fan1998efficient,
	author = {Fan, Jianoing and Yao, Qiwei},
	title = "{Efficient estimation of conditional variance functions in stochastic regression}",
	journal = {Biometrika},
	volume = {85},
	number = {3},
	pages = {645-660},
	year = {1998},
	month = {09},
	abstract = "{Conditional heteroscedasticity has often been used in modelling and understanding the variability of statistical data. Under a general set-up which includes nonlinear time series models as a special case, we propose an efficient and adaptive method for estimating the conditional variance. The basic idea is to apply a local linear regression to the squared residuals. We demonstrate that, without knowing the regression function, we can estimate the conditional variance asymptotically as well as if the regression were given. This asymptotic result, established under the assumption that the observations are made from a strictly stationary and absolutely regular process, is also verified via simulation. Further, the asymptotic result paves the way for adapting an automatic bandwidth selection scheme. An application with financial data illustrates the usefulness of the proposed techniques.}",
	issn = {0006-3444},
	doi = {10.1093/biomet/85.3.645},
	url = {https://doi.org/10.1093/biomet/85.3.645},
	eprint = {https://academic.oup.com/biomet/article-pdf/85/3/645/5781201/85-3-645.pdf},
}
,
@article{ruppert1997local,
	author = { David   Ruppert  and  M. P.   Wand  and  Ulla   Holst  and  Ola   Hösjer },
	title = {Local Polynomial Variance-Function Estimation},
	journal = {Technometrics},
	volume = {39},
	number = {3},
	pages = {262-273},
	year  = {1997},
	publisher = {Taylor & Francis},
	doi = {10.1080/00401706.1997.10485117},
	
	URL = { 
	https://www.tandfonline.com/doi/abs/10.1080/00401706.1997.10485117
	
	},
	eprint = { 
	https://www.tandfonline.com/doi/pdf/10.1080/00401706.1997.10485117
	
	}	
},
@inproceedings{berman2018lovasz,
	title={The lov{\'a}sz-softmax loss: a tractable surrogate for the optimization of the intersection-over-union measure in neural networks},
	author={Berman, Maxim and Rannen Triki, Amal and Blaschko, Matthew B},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={4413--4421},
	year={2018}
}
